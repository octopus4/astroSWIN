{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5RVlpZcZeNUC"
   },
   "source": [
    "# OPENSOURCE BLURXTERMINATOR\n",
    "\n",
    "This jupyter notebook provides all necessary functions to run RUSSIAN opensource astrophotography images sharpening model -- AstroSWIN. This model is a finetune of Image2Image-transformer `caidas/swin2SR-lightweight-x2-64` (original model card is located [here](https://huggingface.co/caidas/swin2SR-lightweight-x2-64/tree/main))\n",
    "\n",
    "Model has been trained in 7 iterations using astrobin and esahubble archive data, all exclusive images rights are belong to their authors, this model cannot be used to reproduce their results or to generate look-alike images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1o6ZFMEj9UY"
   },
   "source": [
    "## Download the model\n",
    "\n",
    "After training I got two primary model checkpoints, v0.6 performs a bit harder sharpening, while v0.7 does it more softly. They also differ at sharpening images background, as this was the hardest part of model's training process.\n",
    "\n",
    "Models weights are saved at my personal google drive storage and publicly available for download via link:\n",
    "1. V0.6: https://drive.google.com/file/d/1N6s8O9MESdfOz4uCzbrl4GsKGZhJw2iK/view?usp=sharing\n",
    "2. V0.7: https://drive.google.com/file/d/10ZR4X57PoqXunGMFig4cWo9Ef7X1uz3m/view?usp=sharing\n",
    "\n",
    "Anyone can freely modify this model's architechture and finetune it furthermore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t5m1Ggnqcv-d",
    "outputId": "46109f23-b543-4717-ea96-43d69013a2e0"
   },
   "outputs": [],
   "source": [
    "!gdown 1N6s8O9MESdfOz4uCzbrl4GsKGZhJw2iK -O astroswin.zip && unzip astroswin.zip  # v0.6\n",
    "!gdown 10ZR4X57PoqXunGMFig4cWo9Ef7X1uz3m -O astroswin.zip && unzip astroswin.zip  # v0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WvwHMTi-kVWp"
   },
   "source": [
    "## Initialization\n",
    "\n",
    "Below we define required imports and auxilary functions to load and infer the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WzwB-BIXdHHX"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "from transformers import Swin2SRForImageSuperResolution, Swin2SRImageProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rHJ95NJ6dqEd"
   },
   "outputs": [],
   "source": [
    "class AstroSwin2SR(Swin2SRForImageSuperResolution):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        del self.upsample\n",
    "        self.resample = torch.nn.Conv2d(60, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "\n",
    "    def forward(self, pixel_values: torch.Tensor, labels: torch.Tensor = None):\n",
    "        output = self.swin2sr(pixel_values=pixel_values)\n",
    "        output = self.resample(output.last_hidden_state)\n",
    "        return {'outputs': output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nGN1JBb2dk_0"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "version = 'v0_7'\n",
    "\n",
    "aswin = AstroSwin2SR.from_pretrained(f'astroswin_{version}').eval().to(device)\n",
    "processor = Swin2SRImageProcessor.from_pretrained(f'astroswin_{version}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7GgEKr7Gkchp"
   },
   "source": [
    "## Blur terminating functions\n",
    "\n",
    "Below we define tensor-to-pil format converter and all-in-one image sharpening run function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "49ZxOJ7jeBPf"
   },
   "outputs": [],
   "source": [
    "def tensor_to_pil(tensor: torch.Tensor):\n",
    "    np_values = tensor.numpy()[0]\n",
    "    np_values = np.clip(np_values, 0, 1)\n",
    "    np_values = np.moveaxis(np_values, source=0, destination=-1)\n",
    "    return (np_values * 255.0).round().astype(np.uint8)\n",
    "\n",
    "@torch.no_grad()\n",
    "def terminate_blur(\n",
    "    image: Image, model: AstroSwin2SR, processor: Swin2SRImageProcessor, window: int = 256\n",
    "):\n",
    "    from tqdm import tqdm\n",
    "    from gc import collect\n",
    "\n",
    "    # Создание весовой маски\n",
    "    def create_weight_mask(size, overlap):\n",
    "        mask = torch.ones(1, 1, size + 2 * overlap, size + 2 * overlap)\n",
    "        fade = torch.linspace(0, 1, overlap)\n",
    "\n",
    "        # Вертикальные границы\n",
    "        mask[..., :overlap, :] *= fade.view(1, 1, -1, 1)\n",
    "        mask[..., -overlap:, :] *= fade.flip(0).view(1, 1, -1, 1)\n",
    "\n",
    "        # Горизонтальные границы\n",
    "        mask[..., :, :overlap] *= fade.view(1, 1, 1, -1)\n",
    "        mask[..., :, -overlap:] *= fade.flip(0).view(1, 1, 1, -1)\n",
    "        return mask.to(device)\n",
    "\n",
    "    pad = 32\n",
    "    pad_based_width, pad_based_height = (image.width // window + 1) * window, (image.height // window + 1) * window\n",
    "\n",
    "    img_tensor = processor(image, return_tensors='pt').pixel_values.to(device)\n",
    "    pad_based_img = torch.zeros(1, 3, pad_based_height, pad_based_width).to(device)\n",
    "    pad_based_img[:, :, :img_tensor.shape[-2], :img_tensor.shape[-1]] += img_tensor\n",
    "    target = torch.zeros_like(pad_based_img)\n",
    "    weight_sum = torch.zeros_like(target)\n",
    "    weight_mask = create_weight_mask(window, pad)\n",
    "\n",
    "    for x in tqdm(range(0, pad_based_width, window)):\n",
    "        for y in range(0, pad_based_height, window):\n",
    "            # calculate coordinates\n",
    "            x_from = max(0, x - pad)\n",
    "            y_from = max(0, y - pad)\n",
    "            x_to = x + min(window + pad, pad_based_width - x)\n",
    "            y_to = y + min(window + pad, pad_based_height - y)\n",
    "            # pass patch through model\n",
    "            patch_tensor = pad_based_img[:, :, y_from:y_to, x_from:x_to]\n",
    "            outputs = model(pixel_values=patch_tensor)['outputs'].detach()\n",
    "            # apply mask\n",
    "            mask_x_from = 0 if x_from - pad >= 0 else pad # 0 если маска и патч влезают полностью; pad, если нужно кропнуть\n",
    "            mask_y_from = 0 if y_from - pad >= 0 else pad\n",
    "            mask_x_to = window + 2 * pad if x_to + pad <= pad_based_width else window + pad # win+2pad если маска влезает справа полностью; win+pad, если нужно кропнуть\n",
    "            mask_y_to = window + 2 * pad if y_to + pad <= pad_based_height else window + pad\n",
    "            # add patch\n",
    "            cropped_mask = weight_mask[:, :, mask_y_from:mask_y_to, mask_x_from:mask_x_to]\n",
    "            target[:, :, y_from:y_to, x_from:x_to] += outputs * cropped_mask\n",
    "            weight_sum[:, :, y_from:y_to, x_from:x_to] += cropped_mask\n",
    "            #\n",
    "            del outputs\n",
    "        collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    target /= weight_sum.clamp(min=1e-6)\n",
    "    return Image.fromarray(tensor_to_pil(target.cpu()[:, :, :image.height, :image.width]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EFnqz4YclTze"
   },
   "source": [
    "Here I give an example of image processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7NRl62a3eF4i"
   },
   "outputs": [],
   "source": [
    "image = Image.open('rgb_GraXpert_1.tiff').convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_xWpPmZ4iX91",
    "outputId": "5ad2859b-874a-49d0-8fa8-9901409fcb3c"
   },
   "outputs": [],
   "source": [
    "processed = terminate_blur(image, aswin, processor, window=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kiEghKArl9ic"
   },
   "outputs": [],
   "source": [
    "with open('processed_2.tiff', 'wb') as f:\n",
    "    processed.save(f)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
